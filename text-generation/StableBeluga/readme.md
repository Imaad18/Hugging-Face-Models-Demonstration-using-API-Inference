![sb](https://github.com/user-attachments/assets/45375f22-e4fe-44d3-aca8-8fe68bb01727)

# 🐳 StableBeluga 2 - Instruction-Tuned Language Model

This project demonstrates how to use the [StableBeluga 2](https://huggingface.co/stabilityai/StableBeluga2), a powerful instruction-following LLM developed by [Stability AI](https://stability.ai/), for natural language generation tasks using the Hugging Face `transformers` library.

---

## 📌 Model Summary

- **Model**: `stabilityai/StableBeluga2`
- **Type**: Instruction-tuned language model
- **Architecture**: Based on the LLaMA 2 (70B) foundation model
- **Precision**: FP16 (half-precision floating point)
- **Framework**: PyTorch
- **License**: Apache 2.0
- **Provider**: [Stability AI](https://stability.ai/)

---

## 🔧 Features

- Instruction-following with high accuracy and safety alignment
- Ideal for creative tasks, chatbots, summarization, code generation, and general-purpose NLP
- Preconfigured with a **system prompt** for alignment and task conditioning

---

## ⚙️ Setup Instructions

### ✅ 1. Environment Setup

```bash
pip install torch transformers accelerate
```
