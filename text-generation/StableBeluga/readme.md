![sb](https://github.com/user-attachments/assets/45375f22-e4fe-44d3-aca8-8fe68bb01727)

# ğŸ³ StableBeluga 2 - Instruction-Tuned Language Model

This project demonstrates how to use the [StableBeluga 2](https://huggingface.co/stabilityai/StableBeluga2), a powerful instruction-following LLM developed by [Stability AI](https://stability.ai/), for natural language generation tasks using the Hugging Face `transformers` library.

---

## ğŸ“Œ Model Summary

- **Model**: `stabilityai/StableBeluga2`
- **Type**: Instruction-tuned language model
- **Architecture**: Based on the LLaMA 2 (70B) foundation model
- **Precision**: FP16 (half-precision floating point)
- **Framework**: PyTorch
- **License**: Apache 2.0
- **Provider**: [Stability AI](https://stability.ai/)

---

## ğŸ”§ Features

- Instruction-following with high accuracy and safety alignment
- Ideal for creative tasks, chatbots, summarization, code generation, and general-purpose NLP
- Preconfigured with a **system prompt** for alignment and task conditioning

---

## âš™ï¸ Setup Instructions

### âœ… 1. Environment Setup

```bash
pip install torch transformers accelerate
```
