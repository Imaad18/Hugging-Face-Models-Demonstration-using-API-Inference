<img width="318" height="159" alt="hf" src="https://github.com/user-attachments/assets/ab30522f-b925-442b-a4ce-3803d4c8ecab" />


# ğŸ¤— Hugging Face Models Demonstration via API Inference

[![License](https://img.shields.io/github/license/Imaad18/Hugging-Face-Models-Demonstration-using-API-Inference)](./LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![Stars](https://img.shields.io/github/stars/Imaad18/Hugging-Face-Models-Demonstration-using-API-Inference?style=social)](https://github.com/Imaad18/Hugging-Face-Models-Demonstration-using-API-Inference/stargazers)


> A modular, CUDA-accelerated framework for showcasing text generation with Hugging Face models like Phi-3, Mistral, and StableBeluga using local API-style inference.

---

## ğŸ“Œ Project Goals

- âœ… Demonstrate usage of different Hugging Face models for text generation  
- âœ… Provide modular scripts with consistent inference pipelines  
- âœ… Emphasize real-world prompts and system/user/assistant formatting  
- âœ… Enable fast local inference using CUDA (GPU)  
- âœ… Serve as a template for building LLM-based applications  

---

## ğŸ§  Supported Models

| Model Name                   | Parameters | Context Length | Key Features                                     |
|-----------------------------|------------|----------------|--------------------------------------------------|
| Phi-3 Mini (128K Instruct)  | 3.8B       | 128,000        | Lightweight, instruction-tuned, long context     |
| Mistral 7B Instruct v0.2    | 7B         | ~32,000        | Strong general-purpose reasoning & instruction   |
| StableBeluga 2              | ~7B        | ~32,000        | Fine-tuned assistant-style model by Stability AI |

Each model is organized in its own folder inside the `text-generation/` directory, with a dedicated inference script and prompt format.

---

## ğŸ“ Repository Structure

Hugging-Face-Models-Demonstration-using-API-Inference/
â”‚
â”œâ”€â”€ text-generation/
â”‚ â”œâ”€â”€ phi-3-mini/
â”‚ â”‚ â”œâ”€â”€ model_inference.py
â”‚ â”‚ â””â”€â”€ README.md
â”‚ â”œâ”€â”€ mistral/
â”‚ â”‚ â”œâ”€â”€ model_inference.py
â”‚ â”‚ â””â”€â”€ README.md
â”‚ â”œâ”€â”€ stablebeluga/
â”‚ â”‚ â”œâ”€â”€ model_inference.py
â”‚ â”‚ â””â”€â”€ README.md
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md â† This file


Each subfolder has:
- `model_inference.py`: for running the model
- `README.md`: usage guide and examples for that specific model

---

## ğŸ”§ Setup Instructions

### âœ… Requirements

- Python 3.9+
- CUDA-enabled GPU (recommended: 8GB+ VRAM)
- Installed PyTorch with GPU support
- Hugging Face Transformers library

### ğŸ”Œ Installation

Clone the repository and install dependencies:
```bash
git clone https://github.com/Imaad18/Hugging-Face-Models-Demonstration-using-API-Inference.git
cd Hugging-Face-Models-Demonstration-using-API-Inference
pip install -r requirements.txt
```



Each folder contains:

- `main.py` â€“ Clean demo for inference
- `README.md` â€“ Model-specific notes

---

## ğŸš€ Models Demonstrated

| ğŸ§  Model Name | âš™ï¸ Access | ğŸ”— Hugging Face Link |
|--------------|-----------|----------------------|
| DeepSeek R1 Distill | API | [Link](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) |
| Qwen 0.5B Chat | API | [Link](https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat) |
| Mistral 7B Instruct | API | [Link](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) |
| StableBeluga 2 | Local | [Link](https://huggingface.co/stabilityai/StableBeluga2) |
| Phi-3 Mini | Local | [Link](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct) |
| GPT-2 | Local | [Link](https://huggingface.co/gpt2) |

---

## âš™ï¸ Setup & Usage

### ğŸ§ª API-Based Inference (e.g., Qwen, DeepSeek, Mistral)

```bash
# Set your Hugging Face API token
export HF_TOKEN=your_huggingface_token
```

# Example
cd text-generation/Qwen2.5
python main.py


### Author
Imaad Mahmood
ğŸ“ AI Undergraduate | ğŸ§  ML & LLM Enthusiast | ğŸŒ Based in Bahawalpur, Pakistan
ğŸ”— GitHub: @Imaad18
ğŸ“« Email: imaadmahmood18102004@gmail.com
